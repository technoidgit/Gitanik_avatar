#!/bin/bash
# ====================================================
# ğŸ§  Gitanik Avatar - Full Environment Setup (macOS)
# ====================================================
# Builds: llama.cpp + whisper.cpp + installs TTS + downloads models
# ====================================================

echo "ğŸš€ Starting Gitanik Avatar environment setup..."

# ------------------------------------
# 1ï¸âƒ£ Create & activate virtual environment
# ------------------------------------
if [ ! -d "venv" ]; then
  echo "ğŸ“¦ Creating virtual environment..."
  python3 -m venv venv
else
  echo "âœ… Virtual environment already exists."
fi

source venv/bin/activate

# ------------------------------------
# 2ï¸âƒ£ Upgrade pip and install requirements
# ------------------------------------
echo "ğŸ“¥ Installing dependencies..."
pip install --upgrade pip
pip install -r requirements.txt || echo "âš ï¸  No requirements.txt found, skipping."

# ------------------------------------
# 3ï¸âƒ£ Build llama.cpp
# ------------------------------------
echo "ğŸ¦™ Building llama.cpp..."
cd services/llm/llama.cpp || { echo "âŒ llama.cpp folder missing!"; exit 1; }
if [ ! -d "build" ]; then
  mkdir build && cd build
  cmake .. && cmake --build . --config Release
else
  cd build
  cmake --build . --config Release
fi
cd ../../../..  # back to root

# ------------------------------------
# 4ï¸âƒ£ Build whisper.cpp
# ------------------------------------
echo "ğŸ—£ï¸  Building whisper.cpp..."
cd services/asr/whisper.cpp || { echo "âŒ whisper.cpp folder missing!"; exit 1; }
if [ ! -d "build" ]; then
  mkdir build && cd build
  cmake .. && cmake --build . --config Release
else
  cd build
  cmake --build . --config Release
fi
cd ../../../..  # back to root

# ------------------------------------
# 5ï¸âƒ£ Download TinyLlama GGUF model
# ------------------------------------
MODEL_DIR="models"
MODEL_FILE="TinyLlama-1.1B-Chat-v1.0.Q8_0.gguf"
MODEL_URL="https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/TinyLlama-1.1B-Chat-v1.0.Q8_0.gguf"

mkdir -p $MODEL_DIR

if [ ! -f "$MODEL_DIR/$MODEL_FILE" ]; then
  echo "â¬‡ï¸  Downloading TinyLlama model (~1.1 GB)..."
  curl -L -o "$MODEL_DIR/$MODEL_FILE" "$MODEL_URL"
else
  echo "âœ… Model already downloaded."
fi

# ------------------------------------
# 6ï¸âƒ£ Download Coqui TTS model
# ------------------------------------
echo "ğŸ”Š Downloading TTS model (vctk/vits)..."
python -m TTS.utils.manage --download_model "tts_models/en/vctk/vits"

# ------------------------------------
# 7ï¸âƒ£ Success summary
# ------------------------------------
echo "ğŸ‰ Gitanik Avatar setup complete!"
echo ""
echo "ğŸ§© Components ready:"
echo "   - llama.cpp âœ…"
echo "   - whisper.cpp âœ…"
echo "   - Coqui TTS âœ…"
echo "   - TinyLlama model âœ…"
echo ""
echo "ğŸ‘‰ Activate environment: source venv/bin/activate"
echo "ğŸ‘‰ Run LLM from: services/llm/llama.cpp/build/bin/llama-cli"
echo "ğŸ‘‰ Run TTS via: python -m TTS.bin.synthesize"
echo "ğŸ‘‰ Run ASR via: services/asr/whisper.cpp/build/bin/whisper"
